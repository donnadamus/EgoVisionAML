{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation metrics\n",
        "\n",
        "## Reference:\n",
        "https://github.com/huggingface/evaluate\n",
        "\n",
        "### In this notebook:\n",
        "Predictions are extracted from .json files .\n",
        "\n",
        "We are taking into account our manually annotated references in order to compute the following metrics:\n",
        "- BLEU\n",
        "- ROUGE\n",
        "- METEOR"
      ],
      "metadata": {
        "id": "KErXVXAs_K9V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Prima leggiamo il file e lo processiamo riga per riga\n",
        "with open('ground_truth_3versions.txt', 'r') as file:\n",
        "    lines = file.readlines()\n",
        "\n",
        "# Creiamo la struttura references\n",
        "references = []\n",
        "\n",
        "for line in lines:\n",
        "    # Dividiamo la riga usando il punto e virgola come separatore\n",
        "    # strip() rimuove eventuali spazi bianchi all'inizio e alla fine\n",
        "    versions = [ref.strip() for ref in line.split(';')]\n",
        "\n",
        "    # Per ogni riga, creiamo una lista con le tre versioni\n",
        "    # Ogni versione viene messa in una lista singola, come nell'esempio\n",
        "    reference_group = [[version] for version in versions]\n",
        "\n",
        "    # Aggiungiamo il gruppo di reference alla lista principale\n",
        "    references.append(reference_group)\n",
        "\n",
        "# A questo punto, references avrà una struttura come:\n",
        "# [\n",
        "#     [[\"versione1_riga1\"], [\"versione2_riga1\"], [\"versione3_riga1\"]],\n",
        "#     [[\"versione1_riga2\"], [\"versione2_riga2\"], [\"versione3_riga2\"]],\n",
        "#     ...\n",
        "# ]\n",
        "\n",
        "print(references)"
      ],
      "metadata": {
        "id": "E0ErvbF4ARsn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a757d82-8ec3-4b0e-da0b-23e0433ff3f4"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[['The socket is on the wall in the corridor next to the heater'], ['I saw the socket on the wall in the corridor next to the heater'], ['on the wall in the corridor next to the heater']], [['You chopped broccoli'], ['I chopped broccoli'], ['broccoli']], [['You saw the carton on the second shelf next to the plastic parts organizer'], ['I saw the carton on the second shelf next to the plastic parts organizer'], ['on the second shelf next to the plastic parts organizer']], [['You put the spice in the pot'], ['I put the spice in the pot'], ['spice']], [['You put eight green peppers in the minced meat'], ['I put eight green peppers in the minced meat'], ['eight green peppers']], [['You opened six drawers'], ['I opened six drawers'], ['six drawers']], [['You first used an impact wrench on the machine'], ['I first used an impact wrench on the machine'], ['impact wrench']], [['The genre book was in the upper second shelf'], ['The genre book was in the upper second shelf'], ['upper second shelf']], [['You first hit the tent stick into the ground'], ['I first hit the tent stick into the ground'], ['tent stick']], [['You put oil in the dough in the mixer'], ['I put oil in the dough in the mixer'], ['oil']], [['You spread six slices of bread with peanut butter'], ['I spread six slices of bread with peanut butter'], ['six slices']], [['The Sofa is beige'], ['The Sofa is beige'], ['beige']], [['Yes, you wiped the kitchen counter'], ['Yes, I wiped the kitchen counter'], ['yes']], [['No, you closed the car door'], ['No, I closed the car door'], ['no']], [['You washed the white chopping board'], ['I washed the white chopping board'], ['white chopping board']], [['The plate was in the lower second shelf of the cupboard'], ['The plate was in the lower second shelf of the cupboard'], ['lower second shelf of the cupboard']], [['The egg was in the fridge'], ['The egg was in the fridge'], ['in the fridge']], [['You took a coke'], ['I took a coke'], ['coke']], [['You talked to a man'], ['I talked to a man'], ['a man']], [['You took two plates'], ['I took two plates'], ['two plates']], [['You saw it on a shelf next to the window'], ['I saw it on a shelf next to the window'], ['on a shelf next to the window']], [['You washed socks'], ['I washed socks'], ['socks']], [['The transparent keg was on the shelf'], ['The transparent keg was on the shelf'], ['on the shelf']], [['You rolled 2 doughs'], ['I rolled 2 doughs'], ['2 doughs']], [['The round brush was on the floor'], ['The round brush was on the floor'], ['on the floor']], [['I arranged some kitchen tools in the dishwasher racks'], ['You arranged some kitchen tools in the dishwasher racks'], ['kitchen tools in dishwasher racks']], [['The phone was in my left pocket'], ['The phone was in your left pocket'], ['in left pocket']], [['I used a paint scraper with a black handle and a flat wide metal blade'], ['You used a paint scraper with a black handle and a flat wide metal blade'], ['paint scraper with black handle']], [['I smeared egg on the dough'], ['You smeared egg on the dough'], ['egg']], [['I wiped a square slab of wood'], ['You wiped a square slab of wood'], ['square slab of wood']], [['The plier was in the drawer of the work bench'], ['The plier was in the drawer of the work bench'], ['in the drawer of the work bench']], [['I sharpened the pencils with a box cutter'], ['You sharpened the pencils with a box cutter'], ['box cutter']], [['I unscrewed some bolts'], ['You unscrewed some bolts'], ['bolts']], [['I poured flour and water in the dough mixer'], ['You poured flour and water in the dough mixer'], ['flour and water']], [['The glass was on the table'], ['The glass was on the table'], ['on the table']], [['Yes, I left the fridge open'], ['Yes, you left the fridge open'], ['yes']], [['I put baking trays in the oven'], ['You put baking trays in the oven'], ['baking trays']], [['No, I closed the microwave'], ['No, you closed the microwave'], ['no']], [['I dropped the stainless in a drawer under the cooktop'], ['You dropped the stainless in a drawer under the cooktop'], ['in a drawer under the cooktop']], [['The phone is in my hands'], ['The phone is in your hands'], ['in hands']], [['I cleaned my hands with the blue checkered napkin'], ['You cleaned your hands with the blue checkered napkin'], ['blue checkered napkin']], [['The machine was on the ground in front of the door'], ['The machine was on the ground in front of the door'], ['on the ground in front of the door']], [['I lighted pieces of paper'], ['You lighted pieces of paper'], ['pieces of paper']], [['Yes, I sliced the okro'], ['Yes, you sliced the okro'], ['yes']], [['The phone is on the top shelf of the shelf unit'], ['The phone is on the top shelf of the shelf unit'], ['on the top shelf']], [['I poured cooking oil in the frying pan'], ['You poured cooking oil in the frying pan'], ['cooking oil']], [['I put the ham on the second shelf in the fridge'], ['You put the ham on the second shelf in the fridge'], ['on the second shelf in the fridge']], [['I cut three pieces of tomato'], ['You cut three pieces of tomato'], ['three pieces']], [['I picked two nuts from the black plastic material'], ['You picked two nuts from the black plastic material'], ['two nuts']], [['The plier was in the drawer of the work bench'], ['The plier was in the drawer of the work bench'], ['in the drawer of the work bench']]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Verifichiamo le dimensioni a ogni livello\n",
        "# Livello 1: Numero totale di gruppi di reference\n",
        "numero_gruppi = len(references)\n",
        "print(f\"Numero totale di gruppi di reference: {numero_gruppi}\")\n",
        "\n",
        "# Possiamo anche verificare che ogni gruppo abbia 3 reference\n",
        "# usando una list comprehension\n",
        "numero_reference_per_gruppo = [len(gruppo) for gruppo in references]\n",
        "print(\"\\nNumero di reference per ogni gruppo:\")\n",
        "print(numero_reference_per_gruppo)\n",
        "\n",
        "# Per verificare che la struttura sia coerente, possiamo contare\n",
        "# quanti gruppi hanno esattamente 3 reference\n",
        "gruppi_con_tre_reference = sum(1 for gruppo in references if len(gruppo) == 3)\n",
        "print(f\"\\nGruppi che hanno esattamente 3 reference: {gruppi_con_tre_reference}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wPgo3sNIDd-G",
        "outputId": "bc0da43e-fcb5-4b83-8137-f66d430eece6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Numero totale di gruppi di reference: 50\n",
            "\n",
            "Numero di reference per ogni gruppo:\n",
            "[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
            "\n",
            "Gruppi che hanno esattamente 3 reference: 50\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "# Leggiamo il file JSON\n",
        "with open('VideoLlava_predictions.json', 'r') as file:\n",
        "    # Parserizziamo il contenuto JSON in un oggetto Python\n",
        "    data = json.loads(file.read())\n",
        "\n",
        "# Creiamo la lista delle predictions\n",
        "# Per ogni elemento nel JSON, estraiamo il campo \"prediction\"\n",
        "predictions = []\n",
        "for item in data:\n",
        "    # Estraiamo la prediction e la aggiungiamo alla lista\n",
        "    prediction = item['prediction']\n",
        "    predictions.append(prediction)\n",
        "\n",
        "# A questo punto, predictions sarà una lista di stringhe, dove ogni stringa\n",
        "# è una prediction dal file JSON\n",
        "\n",
        "# Per verificare che la struttura sia corretta, possiamo stampare\n",
        "# le prime predictions come esempio\n",
        "print(\"Esempio delle prime 3 predictions:\")\n",
        "for i, pred in enumerate(predictions[:3], 1):\n",
        "    print(f\"{i}. {pred}\")\n",
        "\n",
        "# Stampiamo anche la lunghezza totale della lista per verifica\n",
        "print(f\"\\nNumero totale di predictions: {len(predictions)}\")\n",
        "\n",
        "print(predictions)"
      ],
      "metadata": {
        "id": "GT0yooJ_C0yl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f51dad1c-6677-4b69-d7c1-623aeeac517a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Esempio delle prime 3 predictions:\n",
            "1. I saw a socket in the image.\n",
            "2. You chopped a head of broccoli.\n",
            "3. I saw a carton in the kitchen.\n",
            "\n",
            "Numero totale di predictions: 50\n",
            "['I saw a socket in the image.', 'You chopped a head of broccoli.', 'I saw a carton in the kitchen.', 'You put a piece of bread in the pot.', 'There are three green peppers in the image.', 'You opened two drawers.', 'The tool you used first on the machine was a screwdriver.', 'The genre book was on a shelf in a bookstore before you picked it up.', 'The first object you hit into the ground is a tent stake.', 'You put flour in the dough in the mixer.', 'I spread peanut butter on two slices of bread.', 'The sofa is blue.', 'Yes, you wiped the kitchen counter.', 'Yes, the car door is open.', 'You washed a chopping board in the sink.', 'The plate was in the refrigerator before you took it out.', 'The egg was in the refrigerator before you picked it.', 'You took a can of soda.', 'In the house, I talked to a woman who was sitting on a couch.', 'The person took two plates from the top shelf.', 'I last saw my wrapper in the kitchen, where I was preparing food.', 'You washed a towel.', 'The transparent keg was sitting on a shelf before you picked it up.', 'The person rolled two doughs.', 'The round brush was picked up from the floor before the woman started brushing her hair.', 'In the kitchen drawer, I arranged a glass bowl, a spoon, and a kn', 'The phone was on a table before you picked it up.', 'You used a red scraper to scrape the tire.', 'L smears orange sauce on the dough.', 'You wiped a wooden block.', 'The plier was on the ground before you picked it up.', 'You sharpened the pencils with a pocket knife.', 'You screwed the blade of a lawn mower.', 'The person in the video poured flour into the dough mixer.', 'The glass was on the counter before you picked it up.', 'Yes, you left the fridge door open, which is why the food is visible in the image', 'L put a tray of doughnuts in the oven.', 'Yes, it appears that the microwave is left open in the kitchen.', 'I dropped the stainless steel bowl on the kitchen floor.', 'Your phone is in your hand.', 'You cleaned your hands with a blue and white checkered napkin.', 'The machine was sitting on the floor before the person opened the door.', 'You lit a cigarette.', 'Yes, you sliced the okro.', \"The phone is in the man's hand.\", 'You poured oil in the frying pan.', 'The ham is in the refrigerator.', 'I cut two pieces of tomato.', 'I picked two nuts from the black plastic material.', 'The plier was on the ground before I picked it up.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "DLpuBxTw-6dt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84d8f19a-2035-47bd-f353-07e5597bb864"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting evaluate\n",
            "  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\n",
            "Collecting datasets>=2.0.0 (from evaluate)\n",
            "  Downloading datasets-3.2.0-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.26.4)\n",
            "Collecting dill (from evaluate)\n",
            "  Downloading dill-0.3.9-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from evaluate) (4.67.1)\n",
            "Collecting xxhash (from evaluate)\n",
            "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess (from evaluate)\n",
            "  Downloading multiprocess-0.70.17-py310-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.10.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.27.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from evaluate) (24.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.16.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (17.0.0)\n",
            "Collecting dill (from evaluate)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting multiprocess (from evaluate)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec>=2021.05.0 (from fsspec[http]>=2021.05.0->evaluate)\n",
            "  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.11.10)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2024.12.14)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2024.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.18.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\n",
            "Downloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading datasets-3.2.0-py3-none-any.whl (480 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, fsspec, dill, multiprocess, datasets, evaluate\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2024.10.0\n",
            "    Uninstalling fsspec-2024.10.0:\n",
            "      Successfully uninstalled fsspec-2024.10.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-3.2.0 dill-0.3.8 evaluate-0.4.3 fsspec-2024.9.0 multiprocess-0.70.16 xxhash-3.5.0\n"
          ]
        }
      ],
      "source": [
        "# Install required packages\n",
        "\n",
        "!pip install evaluate"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install the tokenizer\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n",
        "\n",
        "import evaluate\n",
        "from nltk.tokenize import word_tokenize"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_G3SOWTHJb3s",
        "outputId": "4cac0326-3eed-4276-924d-6269ea2c32f7"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bleu = evaluate.load(\"bleu\")\n",
        "results = bleu.compute(predictions=predictions, references=references, tokenizer=word_tokenize)\n",
        "print(results)\n",
        "\n",
        "results = bleu.compute(predictions=predictions, references=references)\n",
        "print(results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NGoqha4LHGzs",
        "outputId": "bc05f599-78c7-467b-9105-e19a4d1235d6"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'bleu': 0.1768464560302683, 'precisions': [0.39215686274509803, 0.23478260869565218, 0.13658536585365855, 0.07777777777777778], 'brevity_penalty': 1.0, 'length_ratio': 1.6451612903225807, 'translation_length': 510, 'reference_length': 310}\n",
            "{'bleu': 0.1316224824072968, 'precisions': [0.3241650294695481, 0.17429193899782136, 0.09535452322738386, 0.055710306406685235], 'brevity_penalty': 1.0, 'length_ratio': 1.9728682170542635, 'translation_length': 509, 'reference_length': 258}\n"
          ]
        }
      ]
    }
  ]
}