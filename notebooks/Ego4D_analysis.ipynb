{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comprehensive Analysis of Ego4D NLQ Annotations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Required Libraries\n",
    "Import libraries for data manipulation, visualization, and numerical operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard libraries\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Visualization libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Notebook settings\n",
    "plt.style.use('ggplot')\n",
    "sns.set(style=\"whitegrid\", palette=\"deep\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define File Paths\n",
    "Set paths to annotation files and metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files are accessible. Ready to load data.\n"
     ]
    }
   ],
   "source": [
    "# Define paths to data directory and files\n",
    "data_dir = \"data/ego4d_data\"\n",
    "annotations_file = os.path.join(data_dir, \"v1\", \"annotations/nlq_train.json\")\n",
    "metadata_file = os.path.join(data_dir, \"ego4d.json\")\n",
    "\n",
    "# Confirm file existence\n",
    "assert os.path.exists(annotations_file), \"NLQ annotations file not found.\"\n",
    "assert os.path.exists(metadata_file), \"Metadata file not found.\"\n",
    "\n",
    "print(\"All files are accessible. Ready to load data.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load and Inspect the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load NLQ Annotations\n",
    "Load the annotations and inspect the structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-level keys in NLQ annotations: dict_keys(['version', 'date', 'description', 'manifest', 'videos'])\n",
      "Number of videos: 754\n"
     ]
    }
   ],
   "source": [
    "# Load NLQ annotations\n",
    "with open(annotations_file, 'r') as f:\n",
    "    nlq_data = json.load(f)\n",
    "\n",
    "print(\"Top-level keys in NLQ annotations:\", nlq_data.keys())\n",
    "print(\"Number of videos:\", len(nlq_data['videos']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Metadata\n",
    "Load the metadata file and inspect its structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-level keys in Metadata: dict_keys(['date', 'version', 'description', 'videos', 'clips', 'concurrent_video_sets', 'physical_settings', 'moments_labels'])\n",
      "Number of videos in Metadata: 9645\n"
     ]
    }
   ],
   "source": [
    "# Load metadata\n",
    "with open(metadata_file, 'r') as f:\n",
    "    metadata = json.load(f)\n",
    "\n",
    "print(\"Top-level keys in Metadata:\", metadata.keys())\n",
    "print(\"Number of videos in Metadata:\", len(metadata['videos']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "queries:\n",
      "Where did I put a meat container.\n"
     ]
    }
   ],
   "source": [
    "print(\"queries:\")\n",
    "print(nlq_data['videos'][0][\"clips\"][0]['annotations'][1]['language_queries'][3][\"query\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform Data into a DataFrame\n",
    "Extract relevant fields from the NLQ annotations into a structured DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLQ Annotations DataFrame:\n",
      "                              video_uid                              clip_uid  \\\n",
      "0  d250521e-5197-44aa-8baa-2f42b24444d2  fae92e70-88aa-4b77-b41a-5879b74c804c   \n",
      "1  d250521e-5197-44aa-8baa-2f42b24444d2  fae92e70-88aa-4b77-b41a-5879b74c804c   \n",
      "2  d250521e-5197-44aa-8baa-2f42b24444d2  fae92e70-88aa-4b77-b41a-5879b74c804c   \n",
      "3  d250521e-5197-44aa-8baa-2f42b24444d2  fae92e70-88aa-4b77-b41a-5879b74c804c   \n",
      "4  d250521e-5197-44aa-8baa-2f42b24444d2  fae92e70-88aa-4b77-b41a-5879b74c804c   \n",
      "\n",
      "                                               query  \\\n",
      "0       How many frying pans can i see on the shelf?   \n",
      "1  What colour bowl did i carry from the plate st...   \n",
      "2             In what location did i see the basket?   \n",
      "3                       What did i pour in the bowl?   \n",
      "4          Where was the soap before i picked it up?   \n",
      "\n",
      "                                            template              slot_x  \\\n",
      "0         Objects: How many Xâ€™s? (quantity question)         frying pans   \n",
      "1                           Objects: What X did I Y?         colour bowl   \n",
      "2     Objects: In what location did I see object X ?    i See the basket   \n",
      "3                      Objects: What did I put in X?  I Pour in the bowl   \n",
      "4  Objects: Where is object X before / after even...                soap   \n",
      "\n",
      "                  verb_x                        slot_y verb_y  clip_start_sec  \\\n",
      "0  [verb_not_applicable]            i See on the shelf    see         0.00000   \n",
      "1  [verb_not_applicable]  I Carry from the plate stand  carry        55.80900   \n",
      "2                    see                           N/A    N/A        62.70855   \n",
      "3                   pour                           N/A    N/A       150.49668   \n",
      "4  [verb_not_applicable]                i picked it up   pick         7.16000   \n",
      "\n",
      "   clip_end_sec  video_start_sec  video_end_sec  video_start_frame  \\\n",
      "0       43.6657         0.021029      43.686729                  1   \n",
      "1       60.2600        55.830029      60.281029               1675   \n",
      "2       72.2100        62.729579      72.231029               1882   \n",
      "3      154.4890       150.517709     154.510029               4516   \n",
      "4        8.5180         7.181029       8.539029                216   \n",
      "\n",
      "   video_end_frame  duration  \n",
      "0             1311  43.66570  \n",
      "1             1809   4.45100  \n",
      "2             2167   9.50145  \n",
      "3             4636   3.99232  \n",
      "4              257   1.35800  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11292 entries, 0 to 11291\n",
      "Data columns (total 15 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   video_uid          11292 non-null  object \n",
      " 1   clip_uid           11292 non-null  object \n",
      " 2   query              11291 non-null  object \n",
      " 3   template           11230 non-null  object \n",
      " 4   slot_x             10913 non-null  object \n",
      " 5   verb_x             11111 non-null  object \n",
      " 6   slot_y             10702 non-null  object \n",
      " 7   verb_y             11292 non-null  object \n",
      " 8   clip_start_sec     11292 non-null  float64\n",
      " 9   clip_end_sec       11292 non-null  float64\n",
      " 10  video_start_sec    11292 non-null  float64\n",
      " 11  video_end_sec      11292 non-null  float64\n",
      " 12  video_start_frame  11292 non-null  int64  \n",
      " 13  video_end_frame    11292 non-null  int64  \n",
      " 14  duration           11292 non-null  float64\n",
      "dtypes: float64(5), int64(2), object(8)\n",
      "memory usage: 1.3+ MB\n"
     ]
    }
   ],
   "source": [
    "# Initialize list to store extracted data\n",
    "nlq_list = []\n",
    "\n",
    "for video in nlq_data['videos']:\n",
    "    video_uid = video['video_uid']\n",
    "    for clip in video['clips']:\n",
    "        clip_uid = clip['clip_uid']\n",
    "        for annotation in clip['annotations']:\n",
    "            for nlq in annotation['language_queries']:\n",
    "                if 'query' in nlq and nlq[\"query\"] != \"\":\n",
    "                    nlq_list.append({\n",
    "                        'video_uid': video_uid,\n",
    "                        'clip_uid': clip_uid if clip_uid else \"N/A\",  # Replace missing with N/A\n",
    "                        'query': nlq['query'],  # Query is assumed to exist at this point\n",
    "                        'template': nlq['template'] if 'template' in nlq else \"N/A\",\n",
    "                        'slot_x': nlq['slot_x'] if 'slot_x' in nlq else \"N/A\",\n",
    "                        'verb_x': nlq['verb_x'] if 'verb_x' in nlq else \"N/A\",\n",
    "                        'slot_y': nlq['slot_y'] if 'slot_y' in nlq else \"N/A\",\n",
    "                        'verb_y': nlq['verb_y'] if 'verb_y' in nlq else \"N/A\",\n",
    "                        'clip_start_sec': nlq['clip_start_sec'] if 'clip_start_sec' in nlq else 0.0,\n",
    "                        'clip_end_sec': nlq['clip_end_sec'] if 'clip_end_sec' in nlq else 0.0,\n",
    "                        'video_start_sec': nlq['video_start_sec'] if 'video_start_sec' in nlq else 0.0,\n",
    "                        'video_end_sec': nlq['video_end_sec'] if 'video_end_sec' in nlq else 0.0,\n",
    "                        'video_start_frame': nlq['video_start_frame'] if 'video_start_frame' in nlq else 0,\n",
    "                        'video_end_frame': nlq['video_end_frame'] if 'video_end_frame' in nlq else 0,\n",
    "                        'duration': (nlq['clip_end_sec'] - nlq['clip_start_sec']) \n",
    "                                    if 'clip_end_sec' in nlq and 'clip_start_sec' in nlq else 0.0\n",
    "                    })\n",
    "\n",
    "# Convert to DataFrame\n",
    "nlq_df = pd.DataFrame(nlq_list)\n",
    "\n",
    "# Display overview\n",
    "print(\"NLQ Annotations DataFrame:\")\n",
    "print(nlq_df.head())\n",
    "nlq_df.info()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
